# ğŸš€ Logic Depth Prediction using XGBoost

## ğŸ“Œ Overview
This project predicts **combinational logic depth** based on **circuit parameters** using **Machine Learning (XGBoost)**.  
It uses circuit features like **Fan-In, Fan-Out, Gate Count, Path Delay, Netlist Depth, Critical Path Length, and Average Load** to make accurate predictions.

---

## ğŸ“‚ Project Structure
```
google_girl/
â”‚â”€â”€ data/
â”‚   â”œâ”€â”€ features.csv               # Dataset with logic circuit features
â”‚   â”œâ”€â”€ prediction_results.txt      # Predictions on test data
â”‚   â”œâ”€â”€ feature_importance.png      # Feature importance visualization
â”‚â”€â”€ models/
â”‚   â”œâ”€â”€ logic_depth_predictor.pkl   # Trained ML model
â”‚â”€â”€ src/
â”‚   â”œâ”€â”€ train_model.py              # Training script
â”‚â”€â”€ README.md                      # Project documentation
```

---

## ğŸ”§ Installation & Usage

### ğŸ“¥ 1. Clone the Repository

### ğŸš€ 2. Install Required Libraries

### ğŸ“Š 3. Train the Model
Run the training script to build the model:

### ğŸ“ˆ 4. Generate Predictions
Run the script to predict logic depth on new circuit data:

---

## ğŸ“Š Feature Importance
The model evaluates the importance of different circuit parameters. The feature importance plot below shows the most significant factors affecting **logic depth**.



---

## ğŸ“œ Dataset
The dataset (`features.csv`) contains logic circuit parameters and their corresponding **logic depth** values.  
Example:

---

## ğŸ† Model Performance
The XGBoost model was trained using **GridSearchCV** to find the best hyperparameters.  
### **ğŸ“Š Model Evaluation Results:**
- **Training Samples:** 19
- **Testing Samples:** 5
- **Best Hyperparameters:** {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}
- **Mean Absolute Error:** 0.320
- **RÂ² Score:** 0.960
